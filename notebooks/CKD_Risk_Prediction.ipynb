{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c83bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Optional: XGBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28991a2",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b385ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (400, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
       "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
       "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
       "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
       "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
       "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path assumes this notebook is in `notebooks/` and data in `../dataset/`\n",
    "data_path = os.path.join('..', 'dataset', 'kidney_disease.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664bbfd0",
   "metadata": {},
   "source": [
    "## Basic cleaning and type conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e854ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification\n",
       "ckd       250\n",
       "notckd    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop id column if present\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop(columns=['id'])\n",
    "\n",
    "# Strip whitespace and tab characters from string columns\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].astype(str).str.replace('\\t', '', regex=False).str.strip()\n",
    "\n",
    "# Original CKD dataset column names\n",
    "numeric_features = ['age', 'bp', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc']\n",
    "categorical_features = ['sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']\n",
    "target_col = 'classification'\n",
    "\n",
    "# Convert numeric-like columns to numeric (coerce errors to NaN)\n",
    "for col in numeric_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Ensure categorical columns are treated as object\n",
    "for col in categorical_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('object')\n",
    "\n",
    "df[target_col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19d99c3",
   "metadata": {},
   "source": [
    "## Encode target and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cba0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ragavan\\AppData\\Local\\Temp\\ipykernel_22008\\2550306922.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y_raw.replace({'ckd': 1, 'notckd': 0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((280, 24), (120, 24))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map classification labels to binary: ckd -> 1, notckd -> 0\n",
    "y_raw = df[target_col].astype(str).str.replace('\\t', '', regex=False).str.strip().str.lower()\n",
    "y = y_raw.replace({'ckd': 1, 'notckd': 0})\n",
    "\n",
    "# Remove rows with unknown target (if any)\n",
    "mask = y.isin([0, 1])\n",
    "df = df[mask].copy()\n",
    "y = y[mask].astype(int)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[target_col])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc588a4",
   "metadata": {},
   "source": [
    "## Preprocessing and RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd89fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy (RF): 0.9928571428571429 +/- 0.008748177652797088\n",
      "Test accuracy (RF): 1.0\n",
      "\n",
      "Confusion matrix (RF):\n",
      "[[45  0]\n",
      " [ 0 75]]\n",
      "\n",
      "Classification report (RF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numeric preprocessing: median imputation + MinMax scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "# Categorical preprocessing: most frequent imputation + ordinal encoding\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, [c for c in numeric_features if c in X.columns]),\n",
    "        ('cat', categorical_transformer, [c for c in categorical_features if c in X.columns])\n",
    "    ]\n",
    ")\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', rf_clf)\n",
    "])\n",
    "\n",
    "# Cross-validation on training set\n",
    "cv_scores = cross_val_score(rf_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print('CV accuracy (RF):', cv_scores.mean(), '+/-', cv_scores.std())\n",
    "\n",
    "# Fit and evaluate on test set\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred = rf_pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy (RF):', accuracy_score(y_test, y_pred))\n",
    "print('\\nConfusion matrix (RF):')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\nClassification report (RF):')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3ee0b",
   "metadata": {},
   "source": [
    "## Logistic Regression and AdaBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c62ed34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy (LogReg): 0.9892857142857142 +/- 0.008748177652797088\n",
      "Test accuracy (LogReg): 1.0\n",
      "\n",
      "Confusion matrix (LogReg):\n",
      "[[45  0]\n",
      " [ 0 75]]\n",
      "\n",
      "Classification report (LogReg):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n",
      "\n",
      "CV accuracy (AdaBoost): 0.9964285714285716 +/- 0.007142857142857162\n",
      "Test accuracy (AdaBoost): 1.0\n",
      "\n",
      "Confusion matrix (AdaBoost):\n",
      "[[45  0]\n",
      " [ 0 75]]\n",
      "\n",
      "Classification report (AdaBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        75\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model using the same preprocessor\n",
    "logreg_clf = LogisticRegression(max_iter=2000, n_jobs=-1) if hasattr(LogisticRegression(), 'n_jobs') else LogisticRegression(max_iter=2000)\n",
    "\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', logreg_clf)\n",
    "])\n",
    "\n",
    "cv_scores_lr = cross_val_score(logreg_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print('CV accuracy (LogReg):', cv_scores_lr.mean(), '+/-', cv_scores_lr.std())\n",
    "\n",
    "logreg_pipeline.fit(X_train, y_train)\n",
    "y_pred_lr = logreg_pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy (LogReg):', accuracy_score(y_test, y_pred_lr))\n",
    "print('\\nConfusion matrix (LogReg):')\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print('\\nClassification report (LogReg):')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# AdaBoost model using the same preprocessor\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "ada_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', ada_clf)\n",
    "])\n",
    "\n",
    "cv_scores_ada = cross_val_score(ada_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print('\\nCV accuracy (AdaBoost):', cv_scores_ada.mean(), '+/-', cv_scores_ada.std())\n",
    "\n",
    "ada_pipeline.fit(X_train, y_train)\n",
    "y_pred_ada = ada_pipeline.predict(X_test)\n",
    "\n",
    "print('Test accuracy (AdaBoost):', accuracy_score(y_test, y_pred_ada))\n",
    "print('\\nConfusion matrix (AdaBoost):')\n",
    "print(confusion_matrix(y_test, y_pred_ada))\n",
    "print('\\nClassification report (AdaBoost):')\n",
    "print(classification_report(y_test, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843e155",
   "metadata": {},
   "source": [
    "## XGBoost model (if xgboost is installed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa5f2eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy (XGB): 0.9892857142857142 +/- 0.014285714285714285\n",
      "Test accuracy (XGB): 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "if HAS_XGB:\n",
    "    xgb_clf = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.75,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    ")\n",
    "    \n",
    "    xgb_pipeline = Pipeline(steps=[\n",
    "        ('preprocess', preprocessor),\n",
    "        ('model', xgb_clf)\n",
    "])\n",
    "    \n",
    "    cv_scores_xgb = cross_val_score(xgb_pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    print('CV accuracy (XGB):', cv_scores_xgb.mean(), '+/-', cv_scores_xgb.std())\n",
    "    \n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "    print('Test accuracy (XGB):', accuracy_score(y_test, y_pred_xgb))\n",
    "else:\n",
    "    print('xgboost is not installed; skipping XGB model.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b657e",
   "metadata": {},
   "source": [
    "## Save trained models to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "367cf5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved RandomForest model to: ..\\models\\rf_pipeline.joblib\n",
      "Saved Logistic Regression model to: ..\\models\\logreg_pipeline.joblib\n",
      "Saved AdaBoost model to: ..\\models\\ada_pipeline.joblib\n",
      "Saved XGBoost model to: ..\\models\\xgb_pipeline.joblib\n"
     ]
    }
   ],
   "source": [
    "# Directory to save models (relative to notebook location)\n",
    "models_dir = os.path.join('..', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save RandomForest pipeline\n",
    "rf_path = os.path.join(models_dir, 'rf_pipeline.joblib')\n",
    "joblib.dump(rf_pipeline, rf_path)\n",
    "print('Saved RandomForest model to:', rf_path)\n",
    "\n",
    "# Save Logistic Regression pipeline\n",
    "logreg_path = os.path.join(models_dir, 'logreg_pipeline.joblib')\n",
    "joblib.dump(logreg_pipeline, logreg_path)\n",
    "print('Saved Logistic Regression model to:', logreg_path)\n",
    "\n",
    "# Save AdaBoost pipeline\n",
    "ada_path = os.path.join(models_dir, 'ada_pipeline.joblib')\n",
    "joblib.dump(ada_pipeline, ada_path)\n",
    "print('Saved AdaBoost model to:', ada_path)\n",
    "\n",
    "# Save XGBoost pipeline if available\n",
    "if HAS_XGB:\n",
    "    xgb_path = os.path.join(models_dir, 'xgb_pipeline.joblib')\n",
    "    joblib.dump(xgb_pipeline, xgb_path)\n",
    "    print('Saved XGBoost model to:', xgb_path)\n",
    "else:\n",
    "    print('XGBoost not available; no XGB model saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
