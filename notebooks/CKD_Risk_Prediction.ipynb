{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c83bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Optional: XGBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    HAS_XGB = True\n",
    "except ImportError:\n",
    "    HAS_XGB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28991a2",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b385ec5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (400, 26)\n",
      "\n",
      "Target distribution (cleaned):\n",
      "classification\n",
      "ckd       250\n",
      "notckd    150\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wc</th>\n",
       "      <th>rc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>48.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
       "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
       "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
       "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
       "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
       "\n",
       "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
       "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
       "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
       "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
       "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
       "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path assumes this notebook is in `notebooks/` and data in `../dataset/`\n",
    "data_path = os.path.join('..', 'dataset', 'kidney_disease.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "\n",
    "# Show raw target distribution (after stripping hidden whitespace/tabs)\n",
    "target_preview = df['classification'].astype(str).str.replace('\\t', '', regex=False).str.strip().str.lower()\n",
    "print('\\nTarget distribution (cleaned):')\n",
    "print(target_preview.value_counts(dropna=False))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0705a",
   "metadata": {},
   "source": [
    "## Preprocessing + Model Training (KNNImputer + MinMaxScaler)\n",
    "\n",
    "This section uses the dataset-specific cleaning + binary encoding you provided, then trains models using an `sklearn` pipeline: `KNNImputer → MinMaxScaler → Model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "650581cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ragavan\\AppData\\Local\\Temp\\ipykernel_16344\\2480586326.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = y_raw.replace({'ckd': 1, 'notckd': 0})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (400, 24)\n",
      "y distribution:\n",
      " classification\n",
      "1    250\n",
      "0    150\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "Model: rf\n",
      "CV accuracy: 0.9928571428571429 +/- 0.01428571428571428\n",
      "Test accuracy: 0.9833333333333333\n",
      "Confusion matrix:\n",
      " [[44  1]\n",
      " [ 1 74]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        45\n",
      "           1       0.99      0.99      0.99        75\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.98      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: logreg\n",
      "CV accuracy: 0.9678571428571427 +/- 0.03072259023943795\n",
      "Test accuracy: 0.9833333333333333\n",
      "Confusion matrix:\n",
      " [[45  0]\n",
      " [ 2 73]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        45\n",
      "           1       1.00      0.97      0.99        75\n",
      "\n",
      "    accuracy                           0.98       120\n",
      "   macro avg       0.98      0.99      0.98       120\n",
      "weighted avg       0.98      0.98      0.98       120\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: ada\n",
      "CV accuracy: 0.9785714285714284 +/- 0.0071428571428571175\n",
      "Test accuracy: 0.975\n",
      "Confusion matrix:\n",
      " [[45  0]\n",
      " [ 3 72]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        45\n",
      "           1       1.00      0.96      0.98        75\n",
      "\n",
      "    accuracy                           0.97       120\n",
      "   macro avg       0.97      0.98      0.97       120\n",
      "weighted avg       0.98      0.97      0.98       120\n",
      "\n",
      "\n",
      "============================================================\n",
      "Model: xgb\n",
      "CV accuracy: 0.9785714285714286 +/- 0.02082482819587608\n",
      "Test accuracy: 0.9916666666666667\n",
      "Confusion matrix:\n",
      " [[45  0]\n",
      " [ 1 74]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       1.00      0.99      0.99        75\n",
      "\n",
      "    accuracy                           0.99       120\n",
      "   macro avg       0.99      0.99      0.99       120\n",
      "weighted avg       0.99      0.99      0.99       120\n",
      "\n",
      "Saved rf to: ..\\models\\rf_knnminmax_pipeline.joblib\n",
      "Saved logreg to: ..\\models\\logreg_knnminmax_pipeline.joblib\n",
      "Saved ada to: ..\\models\\ada_knnminmax_pipeline.joblib\n",
      "Saved xgb to: ..\\models\\xgb_knnminmax_pipeline.joblib\n",
      "Exported preprocessed dataset to: ..\\dataset\\kidney_disease_preprocessed_knnminmax.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Helpers: cleaning + dataset-specific encoding ---\n",
    "def clean_text(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.strip().replace('\\t', '')\n",
    "    return value\n",
    "\n",
    "def prepare_xy(raw_df: pd.DataFrame):\n",
    "    df_local = raw_df.copy()\n",
    "\n",
    "    # Clean string columns (fix hidden tabs/spaces)\n",
    "    for col_name in df_local.select_dtypes(include=['object']).columns:\n",
    "        df_local[col_name] = df_local[col_name].apply(clean_text)\n",
    "\n",
    "    # Convert '?' markers into NaN (this dataset contains '?' in numeric-like cols)\n",
    "    df_local = df_local.replace('?', np.nan)\n",
    "\n",
    "    if 'classification' not in df_local.columns:\n",
    "        raise ValueError(\"Expected 'classification' column in dataset\")\n",
    "\n",
    "    # Target: ckd -> 1, notckd -> 0\n",
    "    y_raw = df_local['classification'].astype(str).apply(clean_text).str.lower()\n",
    "    y = y_raw.replace({'ckd': 1, 'notckd': 0})\n",
    "    mask = y.isin([0, 1])\n",
    "    df_local = df_local.loc[mask].copy()\n",
    "    y = y.loc[mask].astype(int)\n",
    "\n",
    "    # Features (drop identifiers + target)\n",
    "    drop_cols = [c for c in ['id', 'classification'] if c in df_local.columns]\n",
    "    X = df_local.drop(columns=drop_cols)\n",
    "\n",
    "    # Force known numeric-like columns into numeric\n",
    "    for col_name in ['pcv', 'wc', 'rc']:\n",
    "        if col_name in X.columns:\n",
    "            X[col_name] = pd.to_numeric(X[col_name], errors='coerce')\n",
    "\n",
    "    # Binary/categorical mappings to 0/1\n",
    "    mapping = {\n",
    "        'rbc': {'normal': 1, 'abnormal': 0},\n",
    "        'pc': {'normal': 1, 'abnormal': 0},\n",
    "        'pcc': {'present': 1, 'notpresent': 0},\n",
    "        'ba': {'present': 1, 'notpresent': 0},\n",
    "        'htn': {'yes': 1, 'no': 0},\n",
    "        'dm': {'yes': 1, 'no': 0},\n",
    "        'cad': {'yes': 1, 'no': 0},\n",
    "        'appet': {'good': 1, 'poor': 0},\n",
    "        'pe': {'yes': 1, 'no': 0},\n",
    "        'ane': {'yes': 1, 'no': 0},\n",
    "    }\n",
    "    for col_name, map_dict in mapping.items():\n",
    "        if col_name in X.columns:\n",
    "            X[col_name] = X[col_name].map(map_dict)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Build X/y\n",
    "X, y = prepare_xy(df)\n",
    "print('X shape:', X.shape)\n",
    "print('y distribution:\\n', y.value_counts())\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Models (all share the same KNN+MinMax preprocessing pipeline)\n",
    "models = {\n",
    "    'rf': RandomForestClassifier(n_estimators=300, random_state=42),\n",
    "    'logreg': LogisticRegression(max_iter=2000),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "}\n",
    "if HAS_XGB:\n",
    "    models['xgb'] = XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=4,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.75,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "    )\n",
    "\n",
    "trained_pipelines = {}\n",
    "for name, clf in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('model', clf),\n",
    "    ])\n",
    "\n",
    "    cv_scores = cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    print('\\n' + '=' * 60)\n",
    "    print(f'Model: {name}')\n",
    "    print('CV accuracy:', cv_scores.mean(), '+/-', cv_scores.std())\n",
    "    print('Test accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification report:\\n', classification_report(y_test, y_pred))\n",
    "\n",
    "    trained_pipelines[name] = pipe\n",
    "\n",
    "# Save trained models\n",
    "models_dir = os.path.join('..', 'models')\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "save_paths = {\n",
    "    'rf': os.path.join(models_dir, 'rf_knnminmax_pipeline.joblib'),\n",
    "    'logreg': os.path.join(models_dir, 'logreg_knnminmax_pipeline.joblib'),\n",
    "    'ada': os.path.join(models_dir, 'ada_knnminmax_pipeline.joblib'),\n",
    "    'xgb': os.path.join(models_dir, 'xgb_knnminmax_pipeline.joblib'),\n",
    "}\n",
    "\n",
    "for name, pipe in trained_pipelines.items():\n",
    "    path = save_paths[name]\n",
    "    joblib.dump(pipe, path)\n",
    "    print('Saved', name, 'to:', path)\n",
    "\n",
    "# Optional: export a fully numeric preprocessed dataset (features scaled; target kept as 0/1)\n",
    "preprocess_only = Pipeline(steps=[\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "])\n",
    "X_all_scaled = preprocess_only.fit_transform(X)\n",
    "df_export = pd.DataFrame(X_all_scaled, columns=X.columns)\n",
    "df_export['classification'] = y.values\n",
    "\n",
    "out_path = os.path.join('..', 'dataset', 'kidney_disease_preprocessed_knnminmax.csv')\n",
    "df_export.to_csv(out_path, index=False)\n",
    "print('Exported preprocessed dataset to:', out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ckd-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
